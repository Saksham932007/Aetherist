# Aetherist Deployment Configuration

# Basic deployment settings
environment: production  # development, staging, production
deployment_type: docker  # docker, kubernetes, aws, local
model_config_path: configs/base_config.yaml
optimize_models: true

# Model optimization settings
optimization_config:
  quantize: true
  quantization_backend: fbgemm
  export_onnx: true
  export_torchscript: true
  optimize_for_inference: true
  enable_dynamic_shapes: false
  batch_size: 1
  image_size: [512, 512]

# Server configuration
server_config:
  host: "0.0.0.0"
  port: 8000
  workers: 1
  max_batch_size: 4
  max_queue_size: 100
  log_level: INFO
  cors_origins:
    - "*"
  enable_auth: false

# Docker configuration
docker_config:
  base_image: "pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime"
  python_version: "3.10"
  port: 8000
  workers: 1
  memory_limit: "8g"
  cpu_limit: "4"
  gpu_support: true

# Kubernetes configuration
kubernetes_config:
  namespace: aetherist
  service_name: aetherist-api
  replicas: 2
  image_tag: latest
  resource_requests:
    cpu: "2"
    memory: "4Gi"
  resource_limits:
    cpu: "4"
    memory: "8Gi"
    nvidia.com/gpu: "1"

# AWS configuration
aws_config:
  region: us-west-2
  instance_type: g4dn.xlarge
  min_capacity: 1
  max_capacity: 5
  target_cpu_utilization: 70
